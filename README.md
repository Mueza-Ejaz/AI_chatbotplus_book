# Physical AI & Humanoid Robotics Textbook

This repository contains the source code for an interactive online textbook on "Physical AI & Humanoid Robotics". The project features a Docusaurus-based frontend for structured learning content and a FastAPI backend powering an AI chatbot for interactive queries.

## Project Structure

This is a monorepo containing two main parts:

*   **`frontend/frontend/`**: The Docusaurus site for the textbook content.
*   **`backend/`**: The FastAPI application for the AI chatbot API and content ingestion.

## Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/gemini-cli/ai-robotics-textbook.git
cd ai-robotics-textbook
```

### 2. Frontend Setup (Docusaurus)

Navigate to the `frontend/frontend` directory and install dependencies:

```bash
cd frontend/frontend
npm install
```

### 3. Backend Setup (FastAPI)

Navigate to the `backend/` directory. It is highly recommended to use a Python virtual environment.

```bash
cd backend
python -m venv venv
# On Windows
./venv/Scripts/activate
# On macOS/Linux
source venv/bin/activate
pip install -r requirements.txt
```

### 4. Environment Variables

Create a `.env` file in the `backend/` directory with the following variables. These are crucial for the chatbot to function.

```
GEMINI_API_KEY="YOUR_GEMINI_API_KEY"
QDRANT_URL="YOUR_QDRANT_CLOUD_URL" # e.g., https://<cluster-id>.qdrant.tech
QDRANT_API_KEY="YOUR_QDRANT_CLOUD_API_KEY"
QDRANT_COLLECTION_NAME="textbook_chapters" # Or your preferred collection name
EMBEDDING_SIZE="768" # Must match the output size of your Gemini embedding model
FASTAPI_URL="http://localhost:8000" # Use your backend's URL in production
```
Replace placeholder values with your actual API keys and service URLs.

## Running the Project

### 1. Start the FastAPI Backend

From the `backend/` directory (with virtual environment activated):

```bash
uvicorn main:app --reload
```
The backend API will be available at `http://localhost:8000`.

### 2. Start the Docusaurus Frontend

From the `frontend/frontend` directory:

```bash
npm start
```
The Docusaurus site will be available at `http://localhost:3000`.

### 3. Ingest Textbook Content

Before using the chatbot, you need to ingest the textbook content into Qdrant. Ensure your FastAPI backend is running before executing this script.

From the project root directory:

```bash
python backend/scripts/ingest_content.py frontend/frontend/docs
```
This script will parse all markdown files in `frontend/frontend/docs`, generate embeddings, and store them in your configured Qdrant instance.

## Testing

### Frontend Tests

From the `frontend/frontend` directory:

```bash
npm test
```

### Backend Tests

From the `backend/` directory (with virtual environment activated):

```bash
pytest
```

## Deployment

### Frontend (Vercel)

The `vercel.json` file at the project root is configured for deployment to Vercel. You can deploy directly via the Vercel CLI or connect your GitHub repository to Vercel.

### Backend (Railway/Render)

The `backend/Procfile` specifies how to run the FastAPI application. You can deploy this to platforms like Railway or Render by connecting your GitHub repository and configuring the environment variables in their respective dashboards.

## Further Documentation

*   **[Feature Specification](specs/1-textbook-docusaurus-chatbot/spec.md)**
*   **[Implementation Plan](specs/1-textbook-docusaurus-chatbot/plan.md)**
*   **[Actionable Tasks](specs/1-textbook-docusaurus-chatbot/tasks.md)**
*   **[Data Model](specs/1-textbook-docusaurus-chatbot/data-model.md)**
*   **[API Contracts](specs/1-textbook-docusaurus-chatbot/contracts/openapi.yaml)**
*   **[Quickstart Guide](specs/1-textbook-docusaurus-chatbot/quickstart.md)**

---
Generated by Gemini CLI.
